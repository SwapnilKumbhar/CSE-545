@article{Ali2015,
title = {A review on feature selection in mobile malware detection},
journal = {Digital Investigation},
volume = {13},
pages = {22-37},
year = {2015},
issn = {1742-2876},
doi = {https://doi.org/10.1016/j.diin.2015.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1742287615000195},
author = {Ali Feizollah and Nor Badrul Anuar and Rosli Salleh and Ainuddin Wahid Abdul Wahab},
keywords = {Mobile malware, Android, Feature selection, Review paper, Mobile operating system},
abstract = {The widespread use of mobile devices in comparison to personal computers has led to a new era of information exchange. The purchase trends of personal computers have started decreasing whereas the shipment of mobile devices is increasing. In addition, the increasing power of mobile devices along with portability characteristics has attracted the attention of users. Not only are such devices popular among users, but they are favorite targets of attackers. The number of mobile malware is rapidly on the rise with malicious activities, such as stealing users data, sending premium messages and making phone call to premium numbers that users have no knowledge. Numerous studies have developed methods to thwart such attacks. In order to develop an effective detection system, we have to select a subset of features from hundreds of available features. In this paper, we studied 100 research works published between 2010 and 2014 with the perspective of feature selection in mobile malware detection. We categorize available features into four groups, namely, static features, dynamic features, hybrid features and applications metadata. Additionally, we discuss datasets used in the recent research studies as well as analyzing evaluation measures utilized.}
}% 

@Inbook{Gunasekera2012,
author="Gunasekera, Sheran",
title="Android Architecture",
bookTitle="Android Apps Security",
year="2012",
publisher="Apress",
address="Berkeley, CA",
pages="1--12",
abstract="Google entered the mobile phone market in a style that only multibillion-dollar companies can afford: it bought a company. In 2005, Google, Inc. purchased Android, Inc. At the time, Android was relatively unknown, despite having four very successful people as its creators. Founded by Andy Rubin, Rich Miner, Chris White, and Nick Sears in 2003, Android flew under the radar, developing an operating system for mobile phones. With a quest to develop a smarter mobile phone that was more aware of its owner's preferences, the team behind the Android operating system toiled away in secrecy. Admitting only that they were developing software for mobile phones, the team remained quiet about the true nature of the Android operating system until the acquisition in 2005.",
isbn="978-1-4302-4063-1",
doi="10.1007/978-1-4302-4063-1_1",
url="https://doi.org/10.1007/978-1-4302-4063-1_1"
}

@online {AOSP2022,
  title="Android Runtime and Dalvik",
  author="Android Documentation",
  organization="Google, Inc.",
  year="2022",
  url="https://source.android.com/docs/core/runtime"
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 url="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html",
 pages={2825--2830},
 year={2011}
}

@Inbook{Suthaharan2016,
author="Suthaharan, Shan",
title="Support Vector Machine",
bookTitle="Machine Learning Models and Algorithms for Big Data Classification: Thinking with Examples for Effective Learning",
year="2016",
publisher="Springer US",
address="Boston, MA",
pages="207--235",
abstract="Support Vector Machine is one of the classical machine learning techniques that can still help solve big data classification problems. Especially, it can help the multidomain applications in a big data environment. However, the support vector machine is mathematically complex and computationally expensive. The main objective of this chapter is to simplify this approach using process diagrams and data flow diagrams to help readers understand theory and implement it successfully. To achieve this objective, the chapter is divided into three parts: (1)Â modeling of a linear support vector machine; (2) modeling of a nonlinear support vector machine; and (3) Lagrangian support vector machine algorithm and its implementations. The Lagrangian support vector machine with simple examples is also implemented using the R programming platform on Hadoop and non-Hadoop systems.",
isbn="978-1-4899-7641-3",
doi="10.1007/978-1-4899-7641-3_9",
url="https://doi.org/10.1007/978-1-4899-7641-3_9"
}

@Inbook{Kramer2013,
author="Kramer, Oliver",
title="K-Nearest Neighbors",
bookTitle="Dimensionality Reduction with Unsupervised Nearest Neighbors",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="13--23",
abstract="This chapter gives an introduction to pattern recognition and machine learning via K-nearest neighbors. Nearest neighbor methods will have an important part to play in this book. The chapter starts with an introduction to foundations in machine learning and decision theory with a focus on classification and regression. For the model selection problem, basic methods like cross-validation are introduced. Nearest neighbor methods are based on the labels of the K-nearest patterns in data space. As local methods, nearest neighbor techniques are known to be strong in case of large data sets and low dimensions. Variants for multi-label classification, regression, and semi supervised learning settings allow the application to a broad spectrum of machine learning problems. Decision theory gives valuable insights into the characteristics of nearest neighbor learning results.",
isbn="978-3-642-38652-7",
doi="10.1007/978-3-642-38652-7_2",
url="https://doi.org/10.1007/978-3-642-38652-7_2"
}

@Article{Biau2016,
author={Biau, G{\'e}rard
and Scornet, Erwan},
title={A random forest guided tour},
journal={TEST},
year={2016},
month={Jun},
day={01},
volume={25},
number={2},
pages={197-227},
abstract={The random forest algorithm, proposed by L. Breiman in 2001, has been extremely successful as a general-purpose classification and regression method. The approach, which combines several randomized decision trees and aggregates their predictions by averaging, has shown excellent performance in settings where the number of variables is much larger than the number of observations. Moreover, it is versatile enough to be applied to large-scale problems, is easily adapted to various ad hoc learning tasks, and returns measures of variable importance. The present article reviews the most recent theoretical and methodological developments for random forests. Emphasis is placed on the mathematical forces driving the algorithm, with special attention given to the selection of parameters, the resampling mechanism, and variable importance measures. This review is intended to provide non-experts easy access to the main ideas.},
issn={1863-8260},
doi={10.1007/s11749-016-0481-7},
url={https://doi.org/10.1007/s11749-016-0481-7}
}

